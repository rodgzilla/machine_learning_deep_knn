{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets \n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General settings and normalization tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size        = 128\n",
    "device            = torch.device('cuda')\n",
    "means             = torch.tensor((0.4914, 0.4822, 0.4465)).to(device)\n",
    "stds              = torch.tensor((0.2023, 0.1994, 0.2010)).to(device)\n",
    "normalize         = lambda x: (x - means) / stds\n",
    "normalize_red     = lambda x: (x - means[0]) / stds[0]\n",
    "normalize_green   = lambda x: (x - means[1]) / stds[1]\n",
    "normalize_blue    = lambda x: (x - means[2]) / stds[2]\n",
    "reverse_normalize = lambda x: (x * stds) + means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(img):\n",
    "    img_data = lambda img: reverse_normalize(img.squeeze().permute(1,2,0)).data.cpu().numpy().clip(0, 1)\n",
    "    plt.imshow(img_data(img))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_cats = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        '../data',\n",
    "        train = True,\n",
    "        download = True,\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(means, stds)\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    shuffle = True,\n",
    "    batch_size = batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR10(\n",
    "        '../data',\n",
    "        train = False,\n",
    "        download = True,\n",
    "        transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(means, stds)\n",
    "            ]\n",
    "        )\n",
    "    ),\n",
    "    shuffle = False,\n",
    "    batch_size = 2 * batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluation tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, n_epochs, log_interval):\n",
    "    model.train()\n",
    "    for epoch in tqdm_notebook(range(n_epochs), desc = 'Epochs'):\n",
    "        for batch_idx, (X, y) in tqdm_notebook(enumerate(train_loader), total = len(train_loader), desc = 'Batches', leave = False):\n",
    "            X, y       = X.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            *_, y_pred = model(X)\n",
    "            loss       = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print(f'Train epoch {epoch}: [{batch_idx * len(X):5d}/{len(train_loader.dataset):5d}] Loss: {loss.item():7.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_set_size = len(test_loader.dataset)\n",
    "    correct_answers = 0\n",
    "    sum_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in tqdm_notebook(test_loader):\n",
    "            X, y             = X.to(device), y.to(device)\n",
    "            *_, y_pred       = model(X)\n",
    "            class_pred       = y_pred.argmax(dim = 1)\n",
    "            correct_answers += (y == class_pred).sum().item()\n",
    "            sum_loss        += criterion(y_pred, y).item()\n",
    "    accuracy = correct_answers / test_set_size\n",
    "    average_loss = sum_loss / len(test_loader)\n",
    "    \n",
    "    return accuracy, average_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3 , 32 , 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(32, 32 , 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(32, 64,  3, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(64, 64,  3, padding = 1)\n",
    "        self.fc1   = nn.Linear(64 * 8 * 8, 128)\n",
    "        self.fc2   = nn.Linear(128      , 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_conv1 = F.dropout(F.relu(self.conv1(x)), 0.2)\n",
    "        out_conv2 = F.dropout(F.relu(self.conv2(out_conv1)), 0.2)\n",
    "        out_pool1 = F.max_pool2d(out_conv2, kernel_size = (2, 2))\n",
    "        out_conv3 = F.dropout(F.relu(self.conv3(out_pool1)), 0.2)\n",
    "        out_conv4 = F.dropout(F.relu(self.conv4(out_conv3)), 0.2)\n",
    "        out_pool2 = F.max_pool2d(out_conv4, kernel_size = (2, 2))\n",
    "        out_view  = out_pool2.view(-1, 64 * 8 * 8)\n",
    "        out_fc    = F.dropout(F.relu(self.fc1(out_view)), 0.2)\n",
    "        out       = self.fc2(out_fc)\n",
    "        \n",
    "        return out_conv1, out_conv2, out_conv3, out_conv4, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn       = CNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(cnn, device, train_loader, optimizer, criterion, 10, len(train_loader) // 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, avg_loss = evaluate(cnn, device, train_loader, criterion)\n",
    "print(f'[Train] Accuracy: {100 * accuracy:5.2f}%, loss: {avg_loss:7.4f}')\n",
    "accuracy, avg_loss = evaluate(cnn, device, test_loader, criterion)\n",
    "print(f'[Test] Accuracy: {100 * accuracy:5.2f}%, loss: {avg_loss:7.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y  = next(iter(test_loader))\n",
    "X     = X.to(device)\n",
    "ex_id = 9\n",
    "img   = X[ex_id].permute(1,2,0)\n",
    "img   = reverse_normalize(img)\n",
    "plt.imshow(img.cpu())\n",
    "print(f'Real label: {y[ex_id].item()}')\n",
    "print(f'Predicted label: {cnn(X.to(device))[-1][ex_id].argmax().item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_adv_example(model, epsilon, criterion, X):\n",
    "    X.requires_grad = True\n",
    "    *_, y_pred      = model(X)\n",
    "    loss            = criterion(y_pred, y_pred.argmax(dim = 1))\n",
    "    loss.backward()\n",
    "    adv_example     = X + epsilon * X.grad.sign()\n",
    "    \n",
    "    # Clamping the result to [0, 1] in each channel.\n",
    "    # I don't think that there exist a multidimensional clamp function.\n",
    "    for channel, norm_func in enumerate([normalize_red, normalize_green, normalize_blue]):\n",
    "        adv_example[:, channel, ...].clamp_(norm_func(0), norm_func(1))\n",
    "    \n",
    "    return adv_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_sample_process(model, epsilon, ex_idx, X, y):\n",
    "    source       = X[ex_idx, ...].unsqueeze(0).to(device)\n",
    "    *_, y_pred   = model(source)\n",
    "    adv_example  = generate_adv_example(model, epsilon, criterion, source)\n",
    "    *_, adv_pred = cnn(adv_example)\n",
    "    for i in range(10):\n",
    "        print(f'Class {i}: {y_pred[0, i]:6.4f} \\t->\\t {adv_pred[0, i]:^6.4f}')\n",
    "    plt.figure(figsize = (15, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    display_img(source)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    display_img(adv_example)\n",
    "    print(f'Real label: {y[ex_idx].item()}')\n",
    "    print(f'Predicted label: {adv_pred[0].argmax().item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_sample_process(cnn, 0.15, 5, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN experimentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_features = [[] for _ in range(4)]\n",
    "targets       = []\n",
    "predictions   = []\n",
    "# c = 0\n",
    "for X, y in tqdm_notebook(train_loader):\n",
    "    X                  = X.to(device)\n",
    "    *out_convs, y_pred = cnn(X)\n",
    "    for i, out_conv in enumerate(out_convs):\n",
    "        conv_feat = out_conv.view(out_conv.size(0), -1).cpu().detach().numpy()\n",
    "        conv_features[i].append(conv_feat)\n",
    "    targets.append(y.numpy())\n",
    "    predictions.append(y_pred.cpu().detach().numpy())\n",
    "#     if c == 5:\n",
    "#         break\n",
    "#     c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_features = [np.concatenate(out_convs) for out_convs in conv_features]\n",
    "targets       = np.concatenate(targets)\n",
    "predictions   = np.concatenate(predictions, axis = 0)\n",
    "print([conv_feat.shape for conv_feat in conv_features])\n",
    "print(targets.shape)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = conv_features[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = 2)\n",
    "X_trans = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "for i, category in enumerate(cifar_cats):\n",
    "    category_inputs = X_trans[targets == i]\n",
    "    plt.scatter(category_inputs[:, 0], category_inputs[:, 1], label = category, alpha = 0.3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "for i, category in enumerate(cifar_cats):\n",
    "    category_inputs = X_trans[np.argmax(predictions, axis = 1) == i]\n",
    "    plt.scatter(category_inputs[:, 0], category_inputs[:, 1], label = category, alpha = 0.3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
